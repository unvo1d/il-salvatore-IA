{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6833d36a",
      "metadata": {
        "id": "6833d36a"
      },
      "source": [
        "# Examen parcial INAR 2022, Diciembre 2022\n",
        "# Parte práctica\n",
        "\n",
        "INSTRUCCIONES:\n",
        "\n",
        "Añade el código python necesario para resolver las tareas planteadas.\n",
        "\n",
        "ES ABSOLUTAMENTE IMPRESCINDIBLE QUE EL CÓDIGO FUNCIONE -SEA PERFECTAMENTE REPRODUCIBLE-. Para ello deberás incorporar todos los import necesarios, y es aconsejable ejecutarlo para verificar que hace lo que se te pide\n",
        "\n",
        "En las instrucciones PARA CADA EJERCICIO se especifica la puntuación para cada uno:\n",
        "\n",
        "- Máximo de puntos\n",
        "- Si la puntuación es TODO O NADA ó PERMITE PUNTUACIÓN PARCIAL\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0bee7ed",
      "metadata": {
        "id": "a0bee7ed"
      },
      "source": [
        "## Escribe aquí tu nombre (p.ej. con un print)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f87aae79",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f87aae79",
        "outputId": "f859df17-894a-44bf-94e5-134ca190099b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pablo\n"
          ]
        }
      ],
      "source": [
        "print(\"Pablo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75f85b20",
      "metadata": {
        "id": "75f85b20"
      },
      "source": [
        "# Ejercicio 1\n",
        "\n",
        "## PUNTUACIÓN MÁXIMA 3\n",
        "## PERMITO PUNTUACIÓN PARCIAL\n",
        "\n",
        "Para hacer un proyecto de clasificación de texto con un target categórico de **3 categorías** has leído que el mejor modelo es uno **multicapa de redes \"fully connected\" -o densas, con 5 capas**  siguiendo la recomendación de que cada capa va resumiendo o consolidando el aprendizaje de las anteriores. \n",
        "\n",
        "Se trata por tanto que implementes código keras para:\n",
        "\n",
        "1. preparar el input a la red con las siguientes especificaciones:\n",
        "\n",
        "- longitud máxima del texto = 250\n",
        "- número máximo de palabras o tokens = 50000\n",
        "- y codificación multi-hot\n",
        "\n",
        "2. definir el modelo de red neuronal\n",
        "3. aprovechar las recomendaciones habituales para optimizar el aprendizaje\n",
        "4. extraer por pantalla la especificación de la red\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8a316863",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a316863",
        "outputId": "a81a8647-c8fa-4827-dccd-161b60a4f966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               32128     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,043\n",
            "Trainable params: 43,043\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Preparar el input a la red\n",
        "max_text_length = 250\n",
        "max_num_words = 50000\n",
        "\n",
        "# Codificación multi-hot con TextVectorization de TensorFlow\n",
        "text_vectorization = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=max_num_words,\n",
        "    output_mode=\"multi_hot\",\n",
        ")\n",
        "\n",
        "# Definir el modelo de red neuronal\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(128, input_shape=(max_text_length,), activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "\n",
        "# Compilar el modelo con las recomendaciones habituales para optimizar el aprendizaje\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Imprimir la especificación de la red\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "882acfde",
      "metadata": {
        "id": "882acfde"
      },
      "source": [
        "# Ejercicio 2\n",
        "\n",
        "## PUNTUACIÓN MÁXIMA 2.5\n",
        "## PERMITO PUNTUACIÓN PARCIAL\n",
        "\n",
        "Se trata de que prepares un modelo de red neuronal para realizar lo que hemos visto como \"Neural Style Transfer\". Y se trata de que utilices para ello la VGG-19 con las siguientes\n",
        "\n",
        "**CAPAS PARA EL EXTRACTOR DE ESTILO**\n",
        "\n",
        "La segunda capa convolucional de cada uno de los bloques de la VGG-19\n",
        "\n",
        "**CAPA PARA EL EXTRACTOR DE CONTENIDO**\n",
        "\n",
        "La tercera capa convolucional del último bloque de la VGG-19\n",
        "\n",
        "Y una vez realizado esto, utilices alguna función estándar para averiguar la dimensionalidad del tensor de salida de esta última capa (la tercera del último bloque de VGG-19 o capa de extractor de contenido)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a665e8c2",
      "metadata": {
        "id": "a665e8c2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.applications.vgg19.VGG19(weights=\"imagenet\", include_top=False)\n",
        "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
        "feature_extractor = keras.Model(inputs=model.inputs, outputs=outputs_dict)\n",
        "\n",
        "style_layer_names = [\n",
        "    \"block1_conv1\",\n",
        "    \"block2_conv1\",\n",
        "    \"block3_conv1\",\n",
        "    \"block4_conv1\",\n",
        "    \"block5_conv1\",\n",
        "]\n",
        "\n",
        "content_layer_name = \"block5_conv2\"\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "WFdOeNffXGhA",
        "outputId": "62b086af-4f32-4780-f5b2-c38af7bb75e5"
      },
      "id": "WFdOeNffXGhA",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2a6f837f173e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg19\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutputs_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfeature_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m style_layer_names = [\n",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "646c76ae",
      "metadata": {
        "id": "646c76ae"
      },
      "source": [
        "# Ejercicio 3: \n",
        "\n",
        "## PUNTUACIÓN MÁXIMA 2.5\n",
        "## TODO O NADA\n",
        "\n",
        "\n",
        "Tengo los siguientes parámetros de una neurona, en un momento concreto del entrenamiento:\n",
        "\n",
        "$$ w = \\begin{pmatrix} 0.3 \\\\ 0.9 \\\\ 0.001 \\end{pmatrix} $$\n",
        "\n",
        "$$ b = 33 $$\n",
        "\n",
        "$$ X = \\begin{pmatrix} 0.1 & 1.0 & 0.2 \\\\ 0.0 & 0.9 & 0.3 \\\\ 0.2 & 0.5 & 1.0 \\end{pmatrix} $$\n",
        "\n",
        "$$ y = \\begin{pmatrix} 0 & 0 & 1 \\end{pmatrix} $$\n",
        "\n",
        "Debes generar código y ejecutarlo que implemente el paso forward de un entrenamiento de gradient descent y muestre el resultado de los siguientes componentes:\n",
        "\n",
        "- dw (o gradiente de los pesos)\n",
        "- db (o gradiente de la bias)\n",
        "- coste\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b237d47c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b237d47c",
        "outputId": "7a223c8e-2cae-495f-e475-04616dd6facd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dw: [[14.56850667]\n",
            " [13.39419   ]\n",
            " [18.73406333]]\n",
            "db: 33.41716666666666\n",
            "cost: 1117.1199930433334\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Parámetros de la neurona\n",
        "w = np.array([0.3, 0.9, 0.001])\n",
        "b = 33\n",
        "\n",
        "# Matriz de entradas X y vector de etiquetas y\n",
        "X = np.array([[0.1, 1.0, 0.2], [0.0, 0.9, 0.3], [0.2, 0.5, 1.0]])\n",
        "y = np.array([[0, 0, 1]])\n",
        "\n",
        "# Hacer predicción\n",
        "y_hat = np.dot(X, w) + b\n",
        "\n",
        "# Calcular coste utilizando la pérdida cuadrática media\n",
        "m = y.shape[1]\n",
        "cost = (1/m) * np.sum((y_hat - y)**2)\n",
        "\n",
        "# Calcular gradientes\n",
        "dw = (1/m) * np.sum((y_hat - y) * X, axis=1, keepdims=True)\n",
        "db = (1/m) * np.sum((y_hat - y))\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"dw:\", dw)\n",
        "print(\"db:\", db)\n",
        "print(\"cost:\", cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45d2835a",
      "metadata": {
        "id": "45d2835a"
      },
      "source": [
        "# Ejercicio 4\n",
        "\n",
        "## PUNTUACIÓN MÁXIMA 2\n",
        "## TODO O NADA\n",
        "\n",
        "\n",
        "A continuación te presento un objeto python, con todos sus componentes. \n",
        "\n",
        "Lo que te pido es CÓDIGO PYTHON para extraer la predicción (yhat) de la epoch 3.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "778a05ce",
      "metadata": {
        "id": "778a05ce"
      },
      "outputs": [],
      "source": [
        "training = { 'hiperparam' :  [1e-4, 10, 32],\n",
        "             'epoch' : ( {'dw': { 1 : [0.12, 0.14, 0.45, 0.66] , \n",
        "                                  2 : [0.01, 0.24, 0.70, 0.05] ,\n",
        "                                  3 : [0.11, 0.44, 0.02, 0.75] ,\n",
        "                                  4 : [0.02, 0.04, 0.72, 0.05] ,\n",
        "                                  5 : [0.72, 0.14, 0.02, 0.15] },\n",
        "                          'yhat': { 1 : '3' , \n",
        "                                    2 : '2' ,\n",
        "                                    3 : '2' ,\n",
        "                                    4 : '3' ,\n",
        "                                    5 : '1' }, \n",
        "                          'time' : { 15.3, \n",
        "                                     12.2,\n",
        "                                     10.9,\n",
        "                                     10.8,\n",
        "                                     10.7} } ) }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = training['epoch']['yhat'][3]\n",
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VAXLmOtlF8ua",
        "outputId": "c0a57175-4829-4717-e064-3bff40b38ba4"
      },
      "id": "VAXLmOtlF8ua",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}